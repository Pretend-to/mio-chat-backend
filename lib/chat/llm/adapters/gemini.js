import BaseLLMAdapter from './base.js'
import { imgUrlToBase64, base64ToImageUrl } from '../../../../utils/imgTools.js'

/**
 * @class OpenAI Bot å®ç°
 */
export default class GeminiAdapter extends BaseLLMAdapter {
  /**
   * è·å–é€‚é…å™¨å…ƒæ•°æ®
   */
  static getAdapterMetadata() {
    return {
      type: 'gemini',
      requiresSpecialAuth: false  // æ ‡å‡† API Key è®¤è¯
    }
  }

  /**
   * æ„é€ å‡½æ•°
   * @param {string} baseUrl - OpenAI API çš„åŸºç¡€ URL
   * @param {string} apiKey - OpenAI API çš„å¯†é’¥
   * @throws {Error} å¦‚æœ baseUrl æˆ– apiKey ç¼ºå¤±,åˆ™æŠ›å‡ºé”™è¯¯
   */
  constructor(geminiConfig) {
    super(geminiConfig)
    this.provider = 'gemini'
  }

  get core() {
    const { base_url, api_key } = this.config
    
    // æ£€æŸ¥ api_key æ˜¯å¦å­˜åœ¨
    if (!api_key) {
      throw new Error('Gemini API Key æœªé…ç½®')
    }
    
    // ä»¥,ä¸ºåˆ†éš”ç¬¦åˆ‡å‰²keyåˆ—è¡¨
    const apiKeys = api_key.split(',')
    // éšæœºé€‰æ‹©ä¸€ä¸ªkey
    const selectedKey = apiKeys[Math.floor(Math.random() * apiKeys.length)]
    // æ—¥å¿—ç”¨çš„å“ªä¸ª
    logger.info(
      `ä½¿ç”¨Gemini APIï¼š${base_url} , ç¬¬${apiKeys.indexOf(selectedKey) + 1}ä¸ªkey`,
    )

    return new Gemini({ base_url, api_key: selectedKey })
  }

  // ---------------------- ç§æœ‰è¾…åŠ©æ–¹æ³• ----------------------

  /**
   * ä» OpenAI API è·å–æ¨¡å‹åˆ—è¡¨
   * @returns {Promise<Array<object>>} æ ¼å¼åŒ–åçš„æ¨¡å‹åˆ—è¡¨
   * @throws {Error} å¦‚æœè·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ï¼Œåˆ™æŠ›å‡ºé”™è¯¯
   */
  async _getModels() {
    try {
      const models = await this.core.models()
      let modelList = this._groupModelsByOwner(models, this.owners)
      return this._sortModelList(modelList)
    } catch (error) {
      logger.error('Failed to get models:', error)
      throw error
    }
  }

  /**
   * é¢„å¤„ç†æ¶ˆæ¯ï¼ˆä¾‹å¦‚ï¼Œå°†å›¾ç‰‡ URL è½¬æ¢ä¸º Base64ï¼‰
   * @private
   * @param {Array<object>} messages - æ¶ˆæ¯æ•°ç»„
   * @returns {Promise<Array<object>>} å¤„ç†åçš„æ¶ˆæ¯æ•°ç»„
   */
  async _processMessages(messages) {
    const processed = []
    for (const message of messages) {
      if (message.role === 'user' && Array.isArray(message.content)) {
        const processedContent = []
        for (const element of message.content) {
          if (element.type === 'image_url') {
            const base64 = element.image_url.url.startsWith('http')
              ? await imgUrlToBase64(element.image_url.url)
              : element.image_url.url
            processedContent.push({
              type: 'image_url',
              image_url: { url: base64.data },
            })
          } else {
            processedContent.push(element)
          }
        }
        processed.push({ ...message, content: processedContent })
      } else {
        processed.push(message)
      }
    }
    return processed
  }

  /**
   * æ‰§è¡ŒèŠå¤©è¯·æ±‚
   * @param {object} body
   * @param {object} e
   * @returns {object}
   */
  async _executeChatRequest(body, e) {
    let callMessage = []
    let cachedMessage = {
      role: 'assistant',
      content: '',
    }

    const stream = this.core.chat(body)
    // e.client.pushConnection(e.request_id, stream)

    for await (const chunk of stream) {
      if (!chunk.candidates || chunk.candidates.length === 0) {
        const { promptFeedback } = chunk
        if (promptFeedback) {
          const Tip = `\n\næœ¬æ¬¡å¯¹è¯å·²è¢«å¼ºåˆ¶ç»“æŸï¼Œç»“æŸåŸå› ï¼š${promptFeedback.blockReason}`
          e.update({
            type: 'content',
            content: Tip,
          })
        }

        continue
      }

      const { content, finishReason, groundingMetadata } = chunk.candidates[0]

      if (content?.parts) {
        for (const part of content.parts) {
          const {
            text,
            functionCall,
            inlineData,
            executableCode,
            codeExecutionResult,
            fileData,
            thought,
          } = part

          if (text) {
            e.update({
              type: thought ? 'reasoningContent' : 'content',
              content: text,
            })
            cachedMessage.content += text
          }

          if (functionCall) {
            const randomId = this._getRandomCallId()

            const toolCallElem = {
              functionCall,
              id: randomId,
            }

            callMessage.push(toolCallElem)

            const toolCallData = {
              name: functionCall.name,
              action: 'started',
              id: randomId,
              parameters: functionCall.args || '',
              result: '',
            }
            e.update({
              type: 'toolCall',
              content: toolCallData,
            })
          }

          if (inlineData) {
            const { data, mimeType } = inlineData
            const avaliableTypes = ['image/png', 'image/jpeg', 'image/gif']
            if (avaliableTypes.includes(mimeType)) {
              const imageUrl = await base64ToImageUrl('', data)
              e.update({
                type: 'content',
                content: `\n![å›¾ç‰‡](${imageUrl})\n`,
              })
            } else {
              logger.warn(`æœªçŸ¥çš„ inlineData ç±»å‹ï¼š${mimeType}`)
              e.update({
                type: 'content',
                content: `\n\næœªçŸ¥çš„ inlineData ç±»å‹ï¼š${mimeType}\n\n`,
              })
            }
          }
          if (executableCode) {
            const { code, language } = executableCode
            const mdCodeTip = `\n\n\`\`\`${language}\n${code}\n\`\`\`\n\n`
            e.update({
              type: 'content',
              content: mdCodeTip,
            })
          }
          if (codeExecutionResult) {
            const { outcome, output } = codeExecutionResult
            if (outcome === 'OUTCOME_OK') {
              const mdCodeTip = `\n\n\`\`\`\n${output}\n\`\`\`\n\n`
              e.update({
                type: 'content',
                content: mdCodeTip,
              })
            } else {
              const errorTip = `\n\næœ¬æ¬¡ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š${output}\n\n`
              e.update({
                type: 'content',
                content: errorTip,
              })
            }
          }
          if (fileData) {
            const { _mimeType, fileUri } = fileData
            const fileTipTemplate = `\n\næ–‡ä»¶ä¸‹è½½é“¾æ¥ï¼š${fileUri}\n\n`
            e.update({
              type: 'content',
              content: fileTipTemplate,
            })
          }
        }
      }

      if (finishReason && finishReason !== 'STOP') {
        const stopTip = `\n\næœ¬æ¬¡å¯¹è¯å·²è¢«å¼ºåˆ¶ç»“æŸï¼Œç»“æŸåŸå› ï¼š${chunk.candidates[0].finishReason}`
        e.update({
          type: 'content',
          content: stopTip,
        })
      }

      if (groundingMetadata) {
        logger.json(groundingMetadata)
      }
    }

    // åœ¨æµå¼å¾ªç¯ç»“æŸåï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·éœ€è¦è°ƒç”¨
    if (callMessage.length > 0) {
      if (cachedMessage.content) {
        e.body.messages.push(cachedMessage)
      }
      return { toolCalls: callMessage }
    }

    return {}
  }

  /**
   * å‡†å¤‡èŠå¤©è¯·æ±‚çš„ä¸»ä½“
   * @param {object} body
   * @returns {object}
   */
  async _prepareChatBody(body) {
    const { messages, settings } = body
    const processedMessages = await this._processMessages(messages)
    const { base, chatParams, toolCallSettings, extraSettings } = settings

    const { tools, mode } = toolCallSettings
    const { gemini } = extraSettings
    const { imageGeneration, internalTools, safetySettings } = gemini
    let parsedTools = undefined
    if (mode !== 'NONE') {
      const validTools = this._getFormattedTools(tools)
      if (validTools.length > 0) {
        parsedTools = {
          function_declarations: validTools,
        }
      }
    }
    const hasInternalTools = Object.values(internalTools).some((value) => value)
    if (hasInternalTools) {
      if (!parsedTools) {
        parsedTools = {}
      }
      Object.keys(internalTools).forEach((key) => {
        if (internalTools[key]) {
          parsedTools[key] = {}
        }
      })
    }
    const parsedSafeSettings = undefined

    const _ = safetySettings ??
      Object.keys(safetySettings).forEach((key) => {
        parsedSafeSettings.push({
          category: key,
          threshold: safetySettings[key],
        })
      })

    const allowed_function_names = mode === 'ANY' ? tools : undefined

    const tool_config = allowed_function_names ? {
      function_calling_config: {
        mode,
        allowed_function_names,
      }
    } : undefined

    const { temperature, reasoning_effort } = chatParams

    const processedChatParams = {
      temperature,
    }

    const avaliableReasoningModels = [
      {
        name: '2.5-pro',
        rangeType: 'pro',
      },
      {
        name: '2.5-flash',
        rangeType: 'flash',
      },
      {
        name: '2.5-flash-light',
        rangeType: 'flash',
      },
    ]

    const reasoningEffortTables = {
      flash: new Map([
        [-1, undefined],
        [0, 0],
        [1, 1024],
        [2, 12800], // ä¸­ç­‰æ¡£ï¼Œé¦™è‰è§‰å¾—ç¨å¾®é«˜ä¸€ç‚¹æ¯”è¾ƒå¥½å–µï¼ğŸŒŸ
        [3, 24576], // æœ€é«˜æ¡£ï¼Œæ»¡è¶³ä½ å•¦ï¼ğŸ’¢
      ]),
      pro: new Map([
        [-1, undefined],
        [0, undefined], // pro ä¸æ”¯æŒå…³é—­æ€è€ƒï¼ŒæŒ‰é»˜è®¤è®¾ç½®
        [1, 8192],
        [2, 16384], // ä¸­ç­‰æ¡£ï¼Œé¦™è‰è§‰å¾—ç¨å¾®é«˜ä¸€ç‚¹æ¯”è¾ƒå¥½å–µï¼ğŸŒŸ
        [3, 32768], // æœ€é«˜æ¡£ï¼Œæ»¡è¶³ä½ å•¦ï¼ğŸ’¢
      ]),
    }

    const isReasoningAvaliable = avaliableReasoningModels.some((model) =>
      base.model.includes(model.name),
    )

    if (isReasoningAvaliable) {
      const rangeType = avaliableReasoningModels.find((model) =>
        base.model.includes(model.name),
      ).rangeType
      const budgetTable = reasoningEffortTables[rangeType]

      const ThinkingConfig = reasoning_effort === 0 ? undefined : {
        includeThoughts: true,
        thinkingBudget: budgetTable.get(reasoning_effort),
      }

      
      processedChatParams.thinkingConfig = ThinkingConfig
      
    }

    if (imageGeneration) {
      processedChatParams.response_modalities = ['Text', 'Image']
    }

    const preparedBody = {
      ...processedChatParams,
      ...base,
      messages: processedMessages,
      safetySettings: parsedSafeSettings,
      tools: parsedTools,
      tool_config,
    }

    return JSON.parse(JSON.stringify(preparedBody))
  }

  /**
   * å¤„ç†å·¥å…·è°ƒç”¨
   * @param {object} toolCalls
   * @param {object} e
   */
  async _handleToolCalls(toolCalls, e) {
    if (!e.body.messages) {
      e.body.messages = [] // ç¡®ä¿ e.body.messages å­˜åœ¨
    }

    Gemini.pushToolCallMessages(e.body.messages, toolCalls)

    const tasks = []

    for (const toolCall of toolCalls) {
      const call = {
        ...toolCall.functionCall,
        arguments: JSON.stringify(toolCall.functionCall.args),
      }

      const toolCallData = {
        name: call.name,
        action: 'running',
        id: toolCall.id,
        parameters: call.args,
        result: '',
      }
      e.update({
        type: 'toolCall',
        content: toolCallData,
      })
      logger.info(`æ‰§è¡Œå·¥å…·ï¼š${call.name}ï¼Œå‚æ•°ï¼š${call.arguments}`)
      logger.debug(JSON.stringify(toolCall, null, 2))

      const runTask = async () => {
        const toolResult = await middleware.llm.runTool(toolCallData, e.user)

        const { call, result } = toolResult

        const pushMessage = {
          name: call.name,
          action: 'finished',
          id: call.id,
          parameters: call.params,
          result: result,
        }

        e.update({
          type: 'toolCall',
          content: pushMessage,
        })

        e.body.messages.push({
          tool_call_id: call.id,
          role: 'tool',
          name: call.name,
          content: result,
        })

        return toolResult
      }

      tasks.push(runTask())
    }

    await Promise.allSettled(tasks)

    // é€’å½’è°ƒç”¨ handleChatRequest æ–¹æ³•æ¥å¤„ç†å·¥å…·è°ƒç”¨çš„ç»“æœ
    await this.handleChatRequest(e, false)
  }
}

export class Gemini {
  constructor({ base_url, api_key }) {
    // if (!base_url || !api_key) {
    //   throw new Error('base_url and api_key are required')
    // }
    this.base_url = base_url
    this.api_key = api_key

    this.cache = ''
  }

  async *chat({
    model,
    messages,
    temperature,
    response_modalities,
    thinkingConfig,
    safetySettings,
    stream,
    tools,
    tool_config,
  }) {
    const url = `${this.base_url}/v1beta/${model}:${
      stream ? 'streamGenerateContent?alt=sse&' : 'generateContent?'
    }key=${this.api_key}`
    const headers = {
      'Content-Type': 'application/json',
    }
    const generationConfig = {
      temperature,
      response_modalities,
      thinkingConfig,
    }
    const { systemInstruction, contents } =
      await this._preProcessMessage(messages)
    const body = {
      system_instruction: systemInstruction,
      generationConfig,
      safetySettings,
      contents,
      tools,
      tool_config,
    }
    logger.json(body)
    try {
      const response = await fetch(url, {
        method: 'POST',
        headers: headers,
        body: JSON.stringify(body),
      })
      if (!response.ok) {
        const errorBody = await response.text()
        throw new Error(errorBody)
      }
      if (stream) {
        yield* this._processStreamResponse(response)
      } else {
        const data = await response.json()
        yield data
      }
    } catch (error) {
      console.error('Error during chat:', error)
      throw error
    }
  }
  async *_processStreamResponse(response) {
    const decoder = new TextDecoder()
    let buffer = ''
    if (!response.body) {
      throw new Error('Response body is null')
    }
    const reader = response.body.getReader()
    try {
      while (true) {
        const { done, value } = await reader.read()
        if (done) {
          // çœ‹çœ‹è¿˜æœ‰æ²¡æœ‰value
          if (value) {
            // è§£æå’Œbuffer
            buffer += decoder.decode(value, { stream: true })
            // äº¤ç»™_parseMutiJsonå¤„ç†
            for (const jsonData of this._parseMutiJson(buffer)) {
              yield jsonData
            }
          }
          break
        }
        buffer += decoder.decode(value, { stream: true })
        // å°è¯•è§£æ buffer ä¸­çš„å®Œæ•´ JSON å¯¹è±¡
        try {
          for (const jsonData of this._parseMutiJson(buffer)) {
            yield jsonData
          }
          buffer = '' // æ¸…ç©º buffer
        } catch {
          logger.error('è§£æJSONå¤±è´¥')
        }
      }
    } catch (error) {
      console.error('Stream processing error:', error)
      throw error
    } finally {
      reader.releaseLock()
    }
  }

  *_parseMutiJson(buffer) {
    console.log(buffer)
    // åˆ†å‰²SSEäº‹ä»¶å¹¶å¤„ç†
    const lines = buffer.split(/\r\n|\n/).filter((line) => line.trim())

    for (const line of lines) {
      // æ£€æŸ¥æ˜¯å¦æ˜¯dataå‰ç¼€
      if (line.startsWith('data: ')) {
        const jsonStr = line.substring(6).trim() // å»æ‰'data: 'å‰ç¼€

        try {
          const jsonData = JSON.parse(jsonStr)
          yield jsonData // ç›´æ¥è¾“å‡ºå®Œæ•´çš„JSONå¯¹è±¡
        } catch {
          // JSONä¸å®Œæ•´æˆ–æ ¼å¼é”™è¯¯ï¼Œæ·»åŠ åˆ°ç¼“å­˜
          this.cache += jsonStr
        }
      } else if (line.trim()) {
        // édataè¡Œä½†æœ‰å†…å®¹ï¼Œå¯èƒ½æ˜¯å…¶ä»–ç±»å‹çš„SSEäº‹ä»¶ï¼Œæ ¹æ®éœ€è¦å¤„ç†
        this.cache += line
      }
      // å°è¯•è§£æç¼“å­˜ä¸­çš„å†…å®¹
      try {
        const cacheData = this.cache.startsWith('data: ')
          ? JSON.parse(this.cache.substring(6).trim())
          : JSON.parse(this.cache)
        yield cacheData
        this.cache = '' // æ¸…ç©ºç¼“å­˜
      } catch {
        // ç¼“å­˜ä¸­çš„å†…å®¹ä»ç„¶ä¸æ˜¯æœ‰æ•ˆJSONï¼Œç»§ç»­ç­‰å¾…æ›´å¤šæ•°æ®
        // console.log(this.cache)
      }
    }
  }

  async models() {
    const url = `${this.base_url}/v1beta/models?key=${this.api_key}`

    const response = await fetch(url, {
      method: 'GET',
    })

    if (!response.ok) {
      const errorBody = await response.text() // Or response.json() if API returns JSON error
      throw new Error(
        `HTTP error! status: ${response.status}, body: ${errorBody}`,
      )
    } else {
      const avaliableModelNames = ['gemma', 'gemini-2.', 'gemini-1.5']
      const res = await response.json()
      const { models } = res

      return models
        .map((model) => {
          return {
            id: model.name,
          }
        })
        .filter((model) => {
          for (const name of avaliableModelNames) {
            if (model.id.includes(name)) {
              return true
            }
          }
        })
    }
  }

  async _preProcessMessage(messages) {
    let systemInstruction = undefined
    let contents = []
    let toolCallResultsCache = []
    for (const [index, message] of messages.entries()) {
      if (message.role === 'system' || message.role === 'developer') {
        // çœ‹çœ‹contentæ˜¯ä¸æ˜¯å­—ç¬¦ä¸²
        if (typeof message.content === 'string') {
          if (!systemInstruction) {
            systemInstruction = {
              parts: [
                {
                  text: message.content,
                },
              ],
            }
          } else {
            systemInstruction.parts.push({
              text: message.content,
            })
          }
        } else {
          logger.error('system message content is not string')
        }
      } else if (message.role === 'user' || message.role === 'assistant') {
        const role = message.role === 'user' ? 'user' : 'model'
        const contentElement = {
          role: role,
          parts: [],
        }
        if (Array.isArray(message.content)) {
          for (const element of message.content) {
            if (element.type === 'text') {
              contentElement.parts.push({
                text: element.text,
              })
            } else if (element.type === 'image_url') {
              if (element.image_url.url.startsWith('http')) {
                logger.error('æš‚ä¸æ”¯æŒhttpå›¾ç‰‡')
              } else {
                // ä»base64ä¸­è§£æå‡ºtypeå’Œdata
                const base64 = element.image_url.url
                const mime_type = base64.split(';')[0].split(':')[1]
                const data = base64.split(',')[1]

                contentElement.parts.push({
                  inline_data: {
                    mime_type,
                    data,
                  },
                })
              }
            }
          }
        } else if (typeof message.content === 'string') {
          contentElement.parts.push({
            text: message.content,
          })
        } else if (message.tool_calls) {
          for (const toolCall of message.tool_calls) {
            const name = toolCall.function.name
            let args = toolCall.function.arguments
            try {
              args = JSON.parse(args)
            } catch {
              // æ— äº‹å‘ç”Ÿ
            }
            const callElm = {
              functionCall: {
                name,
                args,
              },
            }
            contentElement.parts.push(callElm)
          }
        }
        contents.push(contentElement)
      } else if (message.role === 'tool') {
        toolCallResultsCache.push(message)
        // æ£€æŸ¥ä¸‹ä¸€æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯ tool
        if (
          index + 1 < messages.length &&
          messages[index + 1].role === 'tool'
        ) {
          continue
        } else {
          const contentElement = {
            role: 'user',
            parts: [],
          }
          for (const toolCallResult of toolCallResultsCache) {
            const elem = {
              functionResponse: {
                name: toolCallResult.name,
                response: {
                  name: toolCallResult.name,
                  content: toolCallResult.content,
                },
              },
            }
            contentElement.parts.push(elem)
          }
          contents.push(contentElement)
          // æ¸…ç©ºç¼“å­˜
          toolCallResultsCache = []
        }
      } else {
        logger.error(`Unknown role: ${message.role}`)
      }
    }
    return {
      systemInstruction,
      contents,
    }
  }

  // æŠŠ Gemini message push åˆ° openai messages
  static pushToolCallMessages(messages, res) {
    const tool_calls = res.map((res) => {
      return {
        id: res.id,
        type: 'function',
        function: {
          name: res.functionCall.name,
          arguments: res.functionCall.args,
        },
      }
    })
    messages.push({
      role: 'assistant',
      content: null,
      tool_calls,
    })
  }
}
